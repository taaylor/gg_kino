# =============================================================================
# КОНФИГУРАЦИЯ LOGSTASH ДЛЯ ОБРАБОТКИ ЛОГОВ DOCKER КОНТЕЙНЕРОВ
# ==================================================================
# Logstash - это сервер обработки данных, который принимает логи от Filebeat,
# обрабатывает их (парсинг, фильтрация, обогащение) и отправляет в Elasticsearch.
#
# Данная конфигурация выполняет:
# - Прием логов от Filebeat через Beats protocol
# - Парсинг JSON логов и извлечение структурированных данных
# - Обработку специфичных форматов (Kafka, Python traceback)
# - Добавление метаданных и категоризацию логов
# - Очистку от бинарных данных для читаемости
# - Отправку обработанных логов в Elasticsearch
# =============================================================================

# =============================================================================
# ВХОДНОЙ БЛОК (INPUT) - ПРИЕМ ДАННЫХ ОТ FILEBEAT
# =============================================================================
input {
  # Beats input принимает данные от всех агентов Elastic Beats (Filebeat, Metricbeat, etc.)
  beats {
    port => 5044                      # Порт для приема данных от Filebeat
    # client_inactivity_timeout => 60  # Таймаут неактивности клиента (по умолчанию 60с)
    # congestion_threshold => 5         # Порог перегрузки для back-pressure
  }
}

# =============================================================================
# БЛОК ФИЛЬТРОВ (FILTER) - ОБРАБОТКА И ПРЕОБРАЗОВАНИЕ ДАННЫХ
# =============================================================================
filter {
  # Фильтруем избыточные и проблемные MongoDB логи
  if [container][name] =~ /^mongodb_/ {
    drop { }
  }

  # Обрабатываем только события от Docker контейнеров (содержат поле [container])
  if [container] {

    # =========================================================================
    # ПАРСИНГ JSON ЛОГОВ
    # =========================================================================
    # Многие приложения выводят логи в JSON формате для структурированного логирования
    if [message] =~ /^\s*\{.*\}\s*$/ {
      json {
        source => "message"             # Исходное поле для парсинга
        target => "parsed_json"         # Целевое поле для результата парсинга
        add_tag => ["json_parsed"]      # Добавляем тег для успешно распарсенных JSON
        # skip_on_invalid_json => true  # Пропускаем невалидный JSON (по умолчанию false)
      }

      # Извлекаем важные поля из распарсенного JSON
      if "json_parsed" in [tags] {
        # Извлекаем уровень логирования из JSON (level, severity, etc.)
        if [parsed_json][level] {
          mutate {
            add_field => { "log_level" => "%{[parsed_json][level]}" }
          }
        }

        # Извлекаем имя логгера для категоризации сообщений
        if [parsed_json][logger] or [parsed_json][name] {
          mutate {
            add_field => { "logger_name" => "%{[parsed_json][logger]}%{[parsed_json][name]}" }
          }
        }
      }
    }

    # =========================================================================
    # СПЕЦИАЛЬНАЯ ОБРАБОТКА KAFKA ЛОГОВ
    # =========================================================================
    # Kafka логи часто содержат бинарные данные, которые засоряют индекс
    if [message] =~ /kafka\.protocol\.parser/ or [message] =~ /ProduceRequest/ {
      mutate {
        add_tag => ["kafka_log"]          # Помечаем как Kafka лог
        add_field => { "log_category" => "kafka" }  # Добавляем категорию
      }

      # Упрощаем Kafka сообщения, заменяя бинарные данные читаемыми маркерами
      mutate {
        gsub => [
          # Заменяем hex-последовательности (\x00\x1A\xFF) на [HEX]
          "message", "\\\\x[0-9a-fA-F]{2}", "[HEX]",
          # Заменяем бинарные записи records=b'...' на records=[BINARY_DATA]
          "message", "records=b'[^']*'", "records=[BINARY_DATA]",
          # Заменяем любые бинарные строки b'\x...' на [BINARY_DATA]
          "message", "b'\\\\x[^']*'", "[BINARY_DATA]"
        ]
      }
    }

    # =========================================================================
    # ДОБАВЛЕНИЕ МЕТАДАННЫХ DOCKER КОНТЕЙНЕРА
    # =========================================================================
    # Создаем удобные поля для поиска и фильтрации в Kibana
    mutate {
      add_field => {
        "service_name" => "%{[container][name]}"           # Имя сервиса/контейнера
        "docker_image" => "%{[container][image][name]}"    # Имя Docker образа
        "container_id_short" => "%{[container][id]}"       # Полный ID контейнера (будет укорочен)
      }
    }

    # Укорачиваем container ID до 12 символов для читаемости (как в docker ps)
    if [container_id_short] {
      mutate {
        gsub => [ "container_id_short", "^(.{12}).*", "\1" ]
      }
    }

    # =========================================================================
    # АВТОМАТИЧЕСКОЕ ОПРЕДЕЛЕНИЕ УРОВНЯ ЛОГИРОВАНИЯ
    # =========================================================================
    # Если уровень не был извлечен из JSON, пытаемся определить из текста сообщения
    if ![log_level] {
      # Ищем ключевые слова уровней логирования в сообщении (регистронезависимо)
      if [message] =~ /(?i)(ERROR|FATAL|CRITICAL)/ {
        mutate { add_field => { "log_level" => "ERROR" } }
      } else if [message] =~ /(?i)(WARN|WARNING)/ {
        mutate { add_field => { "log_level" => "WARN" } }
      } else if [message] =~ /(?i)(INFO|INFORMATION)/ {
        mutate { add_field => { "log_level" => "INFO" } }
      } else if [message] =~ /(?i)(DEBUG|TRACE)/ {
        mutate { add_field => { "log_level" => "DEBUG" } }
      } else {
        mutate { add_field => { "log_level" => "UNKNOWN" } }
      }
    }

    # =========================================================================
    # СПЕЦИАЛЬНАЯ ОБРАБОТКА PYTHON TRACEBACK
    # =========================================================================
    # Python traceback'и всегда являются ошибками, независимо от уровня в сообщении
    if [message] =~ /Traceback \(most recent call last\)/ {
      mutate {
        add_tag => ["python_traceback"]      # Добавляем тег для поиска
        replace => { "log_level" => "ERROR" } # Принудительно устанавливаем ERROR
      }
    }

    # =========================================================================
    # ОБРАБОТКА КОДИРОВКИ ДЛЯ РУССКИХ СИМВОЛОВ
    # =========================================================================
    # Обеспечиваем корректную обработку UTF-8 символов
    mutate {
      convert => { "message" => "string" }    # Принудительное преобразование в строку
    }

    # =========================================================================
    # ОЧИСТКА НЕНУЖНЫХ ПОЛЕЙ
    # =========================================================================
    # Удаляем служебные поля для экономии места в индексе
    mutate {
      remove_field => [ "agent", "ecs", "host" ]
      # Можно также удалить:
      # - "input" - информация о типе входа
      # - "log" - служебная информация о файле лога
    }
  }
}

# =============================================================================
# ВЫХОДНОЙ БЛОК (OUTPUT) - ОТПРАВКА ДАННЫХ В ELASTICSEARCH
# =============================================================================
output {
  # Основной вывод в Elasticsearch для долгосрочного хранения и поиска
    # hosts => [ "${ES_HOST}" ]                    # Адрес Elasticsearch из переменной среды
    # index => "docker-logs-%{+YYYY.MM.dd}"       # Индекс с датой (новый индекс каждый день)

  if [service_name] {
  elasticsearch {
    hosts => ["${ES_HOST}"]
    index => "logs-%{service_name}"
    action => "create"
    }
  } else {
    elasticsearch {
      hosts => ["${ES_HOST}"]
      index => "logs-common"
      action => "create"
    }
  }

    # Дополнительные настройки для производительности:
    # template_name => "docker-logs"             # Имя шаблона индекса
    # template_pattern => "docker-logs-*"        # Паттерн применения шаблона
    # manage_template => true                    # Управлять шаблоном автоматически
    # ilm_enabled => true                        # Включить Index Lifecycle Management
    # ilm_rollover_alias => "docker-logs"        # Алиас для ILM
  }

  # ОТЛАДОЧНЫЙ ВЫВОД В КОНСОЛЬ (ОТКЛЮЧИТЬ В ПРОДАКШЕНЕ)
  # Полезен для отладки - показывает обработанные события в консоли Logstash
  # stdout {
  #   codec => rubydebug                         # Форматированный вывод для отладки
  # }


# =============================================================================
# ПРИМЕЧАНИЯ ПО ПРОИЗВОДИТЕЛЬНОСТИ И НАСТРОЙКЕ:
# =============================================================================
# 1. ПРОИЗВОДИТЕЛЬНОСТЬ:
#    - При высокой нагрузке увеличьте pipeline.workers в logstash.yml
#    - Настройте pipeline.batch.size для пакетной обработки
#    - Используйте persistent queues для надежности
#
# 2. МОНИТОРИНГ:
#    - Включите X-Pack monitoring для отслеживания производительности
#    - Настройте алерты на заполнение очередей
#    - Отслеживайте метрики JVM и использование памяти
#
# 3. БЕЗОПАСНОСТЬ:
#    - В продакшене включите SSL/TLS для beats input
#    - Настройте аутентификацию для Elasticsearch
#    - Ограничьте сетевые подключения firewall'ом
#
# 4. ОТЛАДКА:
#    - Включите stdout output для просмотра обработанных событий
#    - Используйте condition debugging: if [@metadata][debug] { ... }
#    - Проверяйте логи Logstash на предмет ошибок парсинга
#
# 5. МАСШТАБИРОВАНИЕ:
#    - Запускайте несколько инстансов Logstash за load balancer'ом
#    - Используйте разные pipelines для разных типов логов
#    - Рассмотрите использование Kafka как буфера между Filebeat и Logstash
# =============================================================================
