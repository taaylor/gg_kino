# =============================================================================
# КОНФИГУРАЦИЯ FILEBEAT ДЛЯ СБОРА ЛОГОВ DOCKER КОНТЕЙНЕРОВ
# =============================================================================
# Filebeat - это агент для сбора и отправки логов в ELK стек.
# Данная конфигурация настроена для:
# - Сбора логов всех Docker контейнеров
# - Обработки многострочных сообщений (stacktrace, JSON и т.д.)
# - Пакетной отправки логов в Logstash для повышения производительности
# - Добавления метаданных Docker контейнеров к каждому событию
# =============================================================================

# =============================================================================
# НАСТРОЙКА ВХОДНЫХ ИСТОЧНИКОВ ДАННЫХ (INPUTS)
# =============================================================================
filebeat.inputs:
  - type: filestream # Тип входа - чтение файлов (рекомендуется для новых версий)
    id: docker-container-logs # Уникальный ID для данного input'а
    paths:
      - "/var/lib/docker/containers/*/*.log" # Путь к логам всех Docker контейнеров

    # Парсеры для обработки специфичных форматов логов
    parsers:
      # Парсер для Docker контейнеров - извлекает метаданные из формата Docker
      - container:
          stream: all # Собираем логи из stdout и stderr
          format: auto # Автоматическое определение формата Docker логов

      # Парсер для многострочных сообщений (например, Python traceback, Java stacktrace)
      - multiline:
          type: pattern # Используем регулярные выражения для определения границ сообщений
          # Паттерн определяет НАЧАЛО нового лог-сообщения:
          # - ^\d{4}-\d{2}-\d{2} - строки начинающиеся с даты (2025-06-14)
          # - ^\{ - строки начинающиеся с JSON объекта
          # - ^Traceback|^ERROR|^WARN|^INFO|^DEBUG - строки с уровнями логирования
          pattern: '^\d{4}-\d{2}-\d{2}|^\{|^Traceback|^ERROR|^WARN|^INFO|^DEBUG'
          negate: true # Инвертируем логику: строки НЕ соответствующие паттерну...
          match: after # ...добавляются к предыдущему сообщению
          max_lines: 500 # Максимум 500 строк в одном многострочном сообщении
          timeout: 5s # Таймаут ожидания продолжения многострочного сообщения

    # Дополнительные поля, добавляемые к каждому событию
    fields:
      log_type: docker # Помечаем источник как Docker
      environment: ${ENVIRONMENT:dev} # Окружение (dev/prod/test) из переменной среды
    fields_under_root: false # Поля размещаются в отдельном объекте "fields"
    encoding: utf-8 # Явно указываем кодировку для корректной работы с русскими символами

# =============================================================================
# ОБРАБОТЧИКИ (PROCESSORS)
# =============================================================================
# Процессоры выполняются последовательно и модифицируют события перед отправкой
processors:
  # Добавление метаданных Docker контейнеров
  - add_docker_metadata:
      host: "unix:///var/run/docker.sock" # Подключение к Docker daemon через Unix socket
      match_fields: ["container.id"] # Поле для поиска соответствия контейнера
      labels.dedot: true # Заменяем точки в Docker labels на подчеркивания
      env.dedot: true # Заменяем точки в переменных среды на подчеркивания

  # Удаление ненужных полей для экономии места в индексе
  - drop_fields:
      fields:
        ["agent", "ecs", "host.name", "host.id", "host.architecture", "host.os"]
      ignore_missing: true # Не генерировать ошибку если поле отсутствует

  - decode_json_fields:
      fields: ["message"]
      process_array: false
      max_depth: 2
      target: ""
      overwrite_keys: true
      add_error_key: false

# =============================================================================
# НАСТРОЙКИ ЛОГИРОВАНИЯ FILEBEAT
# =============================================================================
# Настройки собственного логирования Filebeat для отладки
logging.level: debug # Уровень логирования (info для продакшена)
logging.selectors: ["harvester", "input", "filestream"] # Компоненты для детального логирования
logging.to_files: false # Логи в stdout, а не в файлы

# =============================================================================
# НАСТРОЙКИ ПРОИЗВОДИТЕЛЬНОСТИ И ОЧЕРЕДЕЙ
# =============================================================================
# Внутренняя очередь в памяти для пакетной обработки событий
queue.mem:
  events: 3200 # Максимум событий в очереди (больше = больше памяти, выше производительность)
  flush.min_events: 1600 # Отправляем пакет при накоплении 1600 событий
  flush.timeout: 10s # Или принудительно отправляем каждые 10 секунд (даже если событий меньше)

# ВАЖНО: Баланс между производительностью и задержкой:
# - Большие значения = выше производительность, но больше задержка доставки логов
# - Маленькие значения = быстрее доставка, но больше нагрузка на сеть и Logstash

# =============================================================================
# НАСТРОЙКА ВЫВОДА В LOGSTASH
# =============================================================================
output.logstash:
  hosts: ["${LOGSTASH_HOST}:${LOGSTASH_PORT}"] # Адрес Logstash из переменных среды
  compression_level: 3 # Уровень сжатия данных (0-9, 3 - хороший баланс)
  bulk_max_size: 1024 # Максимум событий в одном пакете к Logstash
  template.enabled: false # Отключаем создание шаблонов индекса (делает Logstash)

# =============================================================================
# МОНИТОРИНГ FILEBEAT (ОТКЛЮЧЕН ДЛЯ УПРОЩЕНИЯ ОТЛАДКИ)
# =============================================================================
# Внутренний мониторинг Filebeat - отправляет метрики в Elasticsearch
# monitoring:
#   enabled: false                              # Отключен для упрощения конфигурации
#   elasticsearch:
#     hosts: ["${ELASTIC_LOGS_HOST}:${ELASTIC_LOGS_PORT}"]

# =============================================================================
# ПРИМЕЧАНИЯ ПО НАСТРОЙКЕ:
# =============================================================================
# 1. Filebeat должен работать с правами root для доступа к Docker socket
# 2. Переменные среды (${LOGSTASH_HOST} и т.д.) задаются в .env файле
# 3. При изменении multiline паттернов нужно перезапустить Filebeat
# 4. Для высоконагруженных систем можно увеличить queue.mem.events до 10000+
# 5. В продакшене рекомендуется уменьшить logging.level до "info"
# =============================================================================
